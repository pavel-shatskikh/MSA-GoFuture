# Описание очерёдности выделения сервисов с обоснованием логики

## Подготовка:

API Gateway + версионирование (Strangler-routing v1/v2), Feature Flags, Observability, CI/CD шаблоны.
Шина событий (добавить Kafka/Schema Registry для CDC/аналитики) при сохранении RabbitMQ для Celery/джоб.

## Notification

Минимальный зависимости, проще всего вынести, полезный опыт для команды по миграции. Даёт единый API (SMS, email, FCM,
APNS, Huawei) и трекинг доставок.

## Geography (геопоиск/маршрутизация)

Чёткие границы, внешние интеграции. Разгружает монолит от тяжёлых гео-запросов, полезно для поиска водителей.

## Pricing

Большая ценность для бизнеса. Поскольку ценообразование постоянно меняется, то добавляем Kafka как источник динамических
событий по ценам.

## Driver

Разгружает монолит от частых обновлений статусов/локаций.

## Payments

Четкая граница домена и есть внешняя зависимость на платежные сервисы. Вынести должно быть не сложно, но есть
риски из-за бизнесовой критичности функционала.

## Booking (орchestration, Sagas)

Максимально связанный домен. К этому моменту уже переносим зависимости (Pricing/Driver/Geo/Payments/Notification) и
включаем новый оркестратор с идемпотентностью и сагами.

## Fraud и Analytic - сквозные потребители событий:

Можно начинать раньше (read-only) - не блокируют функционал.

## Вывод

Такой порядок минимизирует риски (сначала слабосвязанные и внешне-интеграционные домены) и даёт пользу в моменте для
расширения функционала сервиса.

# План миграции

## Общее для всех:

- Инвентаризация схем монолита в целевые схемы для каждого нового сервиса.
- Backfill (историческая загрузка) батчами (Spark/Flink в Postgres/ElasticSearch/ClickHouse), валидация подсчётами и выборками.
- CDC (Debezium) из монолита в Kafka (топики на таблицу), outbox-паттерн для событий.
- Двойная запись (dual-write) на транзакциях, пока сервис не станет авторитативным.
- Идемпотентность (ключи, дедупликация), replay поддержан.
- Cutover: канареечный (по региону/тенанту/процентам), фича-флаг.
- Архивация старых данных в S3/ClickHouse, TTL/партиционирование для OLTP.

## Notification

Данные: шаблоны, предпочтения, журналы доставок.
Стратегия: backfill шаблонов/настроек; события отправок остаются в ClickHouse как факт-лог. Монолит вызывает новый API через
адаптер. Cutover мгновенный.

## Geography

Данные: гео-индексы (ES), геозоны, POI, карты.
Стратегия: полная реиндексация в отдельный ES-кластер сервиса; включение только чтений из нового сервиса, затем запись
геозон через него. Canary по регионам.

## Pricing

Данные: тарифы, правила, исторические фичи.
Стратегия: backfill тарифных планов; исторические поездки в ClickHouse для обучения. Runtime: монолит при расчёте цены
обращается к сервису Pricing; затем блокировка цены (price lock) идёт через него. Dual-write ценовых событий в Kafka.

## Driver

Данные: профили, документы, автомобили, статусы, гео-поток.
Стратегия: backfill профилей/авто, последующий CDC для профилей; статусы/локации только в новом сервисе.
Переключение подачи статусов из приложений на новый эндпоинт (по флагу версий SDK).

## Payments

Данные: токены, платежи, холды/капчуры, возвраты.
Стратегия: выделяем boundary: Payment Adapter в монолите в новый Payments. Секреты мигрируются в Vault. История
чеков/транзакций в S3. Canary по частям: сначала новые регионы/новые юзеры, затем миграция старых токенов (по мере
ревалидации).

## Booking

Данные: заказы, статусы поездок, аллокации.
Стратегия: Booking Orchestrator читает события Driver/Pricing/Payments. Исторические поездки остаются read-only в
монолитной БД. Активные поездки не переносятся, cutover запускается ночью так, чтобы новые заказы уходили в
новый сервис (feature-flag). Саги/идемпотентность.

## Fraud

Данные: фичи/правила.
Стратегия: только потребление событий из Kafka + backfill исторических действий в СlickHouse, без блокирующего cutover.

## Analytics Ingest

Данные: события всех доменов.
Стратегия: стандартный конвейер Kafka → Flink/Spark → ClickHouse. Дублируем события из монолита через CDC, из
новых сервисов - нативная публикация.
